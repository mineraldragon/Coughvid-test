{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cf6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from glob import iglob\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8e20f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some constants\n",
    "img_size=128\n",
    "batch_size=32\n",
    "base_learning_rate = 0.0005\n",
    "num_classes=2\n",
    "metadata_path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/metadata_compiled.csv'\n",
    "class1_path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images1/Class_1'\n",
    "class2_path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images1/Class_2'\n",
    "images_path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images1'\n",
    "images_test_set_path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images1_test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "831410c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan:  0\n",
      "healthy:  0\n",
      "symptomatic:  2321\n",
      "Covid:  1034\n"
     ]
    }
   ],
   "source": [
    "data_dir = class2_path\n",
    "\n",
    "#load meta data\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "metadata.count\n",
    "\n",
    "#count how many of each class\n",
    "nan_ctr = 0\n",
    "healthy_ctr = 0\n",
    "symptomatic_ctr = 0\n",
    "COVID_ctr = 0\n",
    "\n",
    "accum_data = pd.DataFrame()\n",
    "for x in os.listdir(data_dir):\n",
    "    if x.endswith('.png'):\n",
    "        path_object = Path(x)\n",
    "        #print(path_object.stem)\n",
    "        q=metadata.loc[metadata['uuid']==path_object.stem]\n",
    "        #print(q['status'].values[0])\n",
    "        tmp = q['status'].values[0]\n",
    "\n",
    "        if tmp == 'healthy':\n",
    "            healthy_ctr += 1\n",
    "        if tmp == 'symptomatic':\n",
    "            symptomatic_ctr += 1\n",
    "        if tmp == 'COVID-19':\n",
    "            COVID_ctr += 1\n",
    "            \n",
    "            \n",
    "print('nan: ', nan_ctr)\n",
    "print('healthy: ', healthy_ctr)\n",
    "print('symptomatic: ', symptomatic_ctr)\n",
    "print('Covid: ', COVID_ctr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5515536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "healthy        12479\n",
       "symptomatic     2590\n",
       "COVID-19        1155\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test_set_directory = False\n",
    "\n",
    "#create test set directory\n",
    "if create_test_set_directory:\n",
    "    \n",
    "    path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images_copy/Symptomatic'\n",
    "    dest_path = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images_test_set_copy/Symptomatic'\n",
    "\n",
    "    files = [f for f in glob.glob(path + \"**/*.png\", recursive=True)]\n",
    "\n",
    "    for f in files:\n",
    "        r = random.randrange(1,100)\n",
    "        if(r<=10):\n",
    "            basename = os.path.basename(f)\n",
    "            file_name = os.path.splitext(basename)[0]\n",
    "            file_destination = os.path.join(dest_path , file_name + '.png')\n",
    "            print('moving ' + f + ' to ' + file_destination)\n",
    "            shutil.move(f, file_destination)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a11a1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_samples = False\n",
    "\n",
    "if copy_samples:\n",
    "\n",
    "    #copy 'symptomatic' samples to training and test folder\n",
    "\n",
    "    training_source = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images_copy/Symptomatic'\n",
    "    test_source = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images_test_set_copy/Symptomatic'\n",
    "\n",
    "    training_dest = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images/Class_2'\n",
    "    test_dest = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Coughvid-dataset/images_test_set/Class_2'\n",
    "\n",
    "    files=os.listdir(training_source)\n",
    "\n",
    "    # iterating over all the files in\n",
    "    # the source directory\n",
    "    for fname in files:\n",
    "\n",
    "        # copying the files to the\n",
    "        # destination directory\n",
    "        shutil.copy2(os.path.join(training_source,fname), training_dest)\n",
    "\n",
    "\n",
    "    files=os.listdir(test_source)\n",
    "\n",
    "    # iterating over all the files in\n",
    "    # the source directory\n",
    "    for fname in files:\n",
    "\n",
    "        # copying the files to the\n",
    "        # destination directory\n",
    "        shutil.copy2(os.path.join(test_source,fname), test_dest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8d073ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14540 files belonging to 2 classes.\n",
      "Using 11632 files for training.\n",
      "Found 14540 files belonging to 2 classes.\n",
      "Using 2908 files for validation.\n",
      "Found 1684 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = images_path\n",
    "\n",
    "#make training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred', \n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=42,\n",
    "    image_size=(img_size, img_size),\n",
    "    crop_to_aspect_ratio=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "#make validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred', \n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    image_size=(img_size, img_size),\n",
    "    crop_to_aspect_ratio=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_set_directory = images_test_set_path\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_set_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    seed=42,\n",
    "    image_size=(img_size, img_size),\n",
    "    crop_to_aspect_ratio=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1c26e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chosen_model = 'MobileNetV2'\n",
    "chosen_model = 'Xception'\n",
    "#chosen_model = 'OwnModel1'\n",
    "\n",
    "if(chosen_model == 'Xception'):\n",
    "    #Xception model\n",
    "    base_model = keras.applications.Xception(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        include_top=False,\n",
    "    )  # Do not include the ImageNet classifier at the top.\n",
    "    \n",
    "    \n",
    "    \n",
    "if(chosen_model == 'MobileNetV2'):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "    )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fa60a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_7 (Rescaling)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_20  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 100)               204900    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,086,681\n",
      "Trainable params: 225,201\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if(chosen_model == 'Xception'):\n",
    "    \n",
    "     # Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "    x = inputs  # Apply random data augmentation\n",
    "\n",
    "    # Pre-trained Xception weights requires that input be scaled\n",
    "    # from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "    # outputs: `(inputs * scale) + offset`\n",
    "    scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "    x = scale_layer(x)\n",
    "\n",
    "    # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base_model is running in inference mode here.\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    #x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "    #x=keras.layers.Dense(1024,activation='relu')(x)\n",
    "    #x=keras.layers.Dense(512,activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    #try this\n",
    "    # flatten the output of the convolutional part: \n",
    "    x = keras.layers.Flatten()(x)\n",
    "    # three hidden layers\n",
    "    x = keras.layers.Dense(100, activation='relu')(x)\n",
    "    x = keras.layers.Dense(100, activation='relu')(x)\n",
    "    x = keras.layers.Dense(100, activation='relu')(x)\n",
    "    # final softmax layer with two categories (dog and cat)\n",
    "    #predictions = keras.layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    \n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(base_learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.AUC()],\n",
    "    )\n",
    "    \n",
    "if(chosen_model == 'MobileNetV2'):\n",
    "    \n",
    "    preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    \n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=(img_size, img_size, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    inputs = tf.keras.Input(shape=(img_size, img_size, 3))\n",
    "    #x = data_augmentation(inputs)\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(.2)(x)\n",
    "    #x=keras.layers.Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    #x=keras.layers.Dense(1024,activation='relu')(x) #dense layer 2\n",
    "    #x=keras.layers.Dense(512,activation='relu')(x) #dense layer 3\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    #outputs = prediction_layer(x) \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                   loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                   metrics=[tf.keras.metrics.Recall()])\n",
    "\n",
    "    \n",
    "    \n",
    "if(chosen_model == 'OwnModel1'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (5, 5), input_shape=(img_size, img_size, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D())\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5f3ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import class_weight\n",
    "\n",
    "#train_label = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "\n",
    "class_weights = {0: 1.,\n",
    "                1: 3.}\n",
    "\n",
    "#class_weights = class_weight.compute_class_weight('balanced', classes = np.unique(train_label), y = train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f5a91319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rogierlandman/opt/anaconda3/envs/VoiceRec1/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 261s 711ms/step - loss: 1.0132 - auc_3: 0.5060 - val_loss: 0.6964 - val_auc_3: 0.5285\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 265s 729ms/step - loss: 1.0064 - auc_3: 0.5347 - val_loss: 0.7140 - val_auc_3: 0.5440\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 267s 734ms/step - loss: 1.0025 - auc_3: 0.5469 - val_loss: 0.7028 - val_auc_3: 0.5359\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 279s 767ms/step - loss: 0.9978 - auc_3: 0.5644 - val_loss: 0.7001 - val_auc_3: 0.5385\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 304s 834ms/step - loss: 0.9909 - auc_3: 0.5830 - val_loss: 0.6918 - val_auc_3: 0.5240\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "if(chosen_model == 'Xception'):\n",
    "    history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, class_weight=class_weights)\n",
    "    \n",
    "if(chosen_model == 'MobileNetV2'):\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight=class_weights)\n",
    "\n",
    "if(chosen_model == 'OwnModel1'):\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d949ce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15f8099d0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "41787ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1024  270]\n",
      " [ 294   96]]\n",
      "F1 score:  0.25396825396825395\n",
      "precision:  0.26229508196721313\n",
      "recall:  0.24615384615384617\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "predictions = model.predict(test_ds)\n",
    "predictions = predictions.ravel()\n",
    "predictions = np.int32(np.round(predictions))\n",
    "\n",
    "test_label = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(test_label, predictions)\n",
    "print(confusion_matrix)\n",
    "\n",
    "F1 = metrics.f1_score(test_label, predictions)\n",
    "print('F1 score: ', F1)\n",
    "\n",
    "precision = metrics.precision_score(test_label, predictions)\n",
    "print('precision: ', precision)\n",
    "\n",
    "recall = metrics.recall_score(test_label, predictions)\n",
    "print('recall: ', recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf8ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 631.844,
   "position": {
    "height": "40px",
    "left": "1059px",
    "right": "20px",
    "top": "80px",
    "width": "552px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
